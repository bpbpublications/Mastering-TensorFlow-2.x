{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference : https://www.kaggle.com/uciml/indian-liver-patient-records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Total_Bilirubin</th>\n",
       "      <th>Direct_Bilirubin</th>\n",
       "      <th>Alkaline_Phosphotase</th>\n",
       "      <th>Alamine_Aminotransferase</th>\n",
       "      <th>Aspartate_Aminotransferase</th>\n",
       "      <th>Total_Protiens</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin_and_Globulin_Ratio</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Total_Bilirubin  Direct_Bilirubin  Alkaline_Phosphotase  \\\n",
       "0   65  Female              0.7               0.1                   187   \n",
       "1   62    Male             10.9               5.5                   699   \n",
       "2   62    Male              7.3               4.1                   490   \n",
       "3   58    Male              1.0               0.4                   182   \n",
       "4   72    Male              3.9               2.0                   195   \n",
       "\n",
       "   Alamine_Aminotransferase  Aspartate_Aminotransferase  Total_Protiens  \\\n",
       "0                        16                          18             6.8   \n",
       "1                        64                         100             7.5   \n",
       "2                        60                          68             7.0   \n",
       "3                        14                          20             6.8   \n",
       "4                        27                          59             7.3   \n",
       "\n",
       "   Albumin  Albumin_and_Globulin_Ratio  Dataset  \n",
       "0      3.3                        0.90        1  \n",
       "1      3.2                        0.74        1  \n",
       "2      3.3                        0.89        1  \n",
       "3      3.4                        1.00        1  \n",
       "4      2.4                        0.40        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pdata = pd.read_csv('../data/indian_liver_patient.csv')\n",
    "pdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field Total_Bilirubin: num 0-entries: 0\n",
      "field Direct_Bilirubin: num 0-entries: 0\n",
      "field Alkaline_Phosphotase: num 0-entries: 0\n",
      "field Alamine_Aminotransferase: num 0-entries: 0\n",
      "field Aspartate_Aminotransferase: num 0-entries: 0\n",
      "field Total_Protiens: num 0-entries: 0\n",
      "field Albumin: num 0-entries: 0\n",
      "field Albumin_and_Globulin_Ratio: num 0-entries: 0\n"
     ]
    }
   ],
   "source": [
    "zero_fields = ['Total_Bilirubin', 'Direct_Bilirubin', 'Alkaline_Phosphotase', 'Alamine_Aminotransferase', \n",
    "               'Aspartate_Aminotransferase','Total_Protiens','Albumin','Albumin_and_Globulin_Ratio']\n",
    "\n",
    "def check_zero_entries(data, fields):\n",
    "    \"\"\" List number of 0-entries in each of the given fields\"\"\"\n",
    "    for field in fields:\n",
    "        print('field %s: num 0-entries: %d' % (field, len(data.loc[ data[field] == 0, field ])))\n",
    "\n",
    "check_zero_entries(pdata, zero_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Gender', 'Total_Bilirubin', 'Direct_Bilirubin', 'Alkaline_Phosphotase', 'Alamine_Aminotransferase', 'Aspartate_Aminotransferase', 'Total_Protiens', 'Albumin', 'Albumin_and_Globulin_Ratio']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = list(pdata.columns.values)\n",
    "features.remove('Dataset')\n",
    "print(features)\n",
    "X = pdata[features]\n",
    "y = pdata['Dataset']\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "#print(X_train.shape)\n",
    "#print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_bind(original_dataframe, feature_to_encode):\n",
    "    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n",
    "    res = pd.concat([original_dataframe, dummies], axis=1)\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Bilirubin</th>\n",
       "      <th>Direct_Bilirubin</th>\n",
       "      <th>Alkaline_Phosphotase</th>\n",
       "      <th>Alamine_Aminotransferase</th>\n",
       "      <th>Aspartate_Aminotransferase</th>\n",
       "      <th>Total_Protiens</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin_and_Globulin_Ratio</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>578</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>579</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>98</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>245</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>184</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>582</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>216</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Total_Bilirubin  Direct_Bilirubin  Alkaline_Phosphotase  \\\n",
       "0                0.7               0.1                   187   \n",
       "1               10.9               5.5                   699   \n",
       "2                7.3               4.1                   490   \n",
       "3                1.0               0.4                   182   \n",
       "4                3.9               2.0                   195   \n",
       "..               ...               ...                   ...   \n",
       "578              0.5               0.1                   500   \n",
       "579              0.6               0.1                    98   \n",
       "580              0.8               0.2                   245   \n",
       "581              1.3               0.5                   184   \n",
       "582              1.0               0.3                   216   \n",
       "\n",
       "     Alamine_Aminotransferase  Aspartate_Aminotransferase  Total_Protiens  \\\n",
       "0                          16                          18             6.8   \n",
       "1                          64                         100             7.5   \n",
       "2                          60                          68             7.0   \n",
       "3                          14                          20             6.8   \n",
       "4                          27                          59             7.3   \n",
       "..                        ...                         ...             ...   \n",
       "578                        20                          34             5.9   \n",
       "579                        35                          31             6.0   \n",
       "580                        48                          49             6.4   \n",
       "581                        29                          32             6.8   \n",
       "582                        21                          24             7.3   \n",
       "\n",
       "     Albumin  Albumin_and_Globulin_Ratio  Gender_Female  Gender_Male  \n",
       "0        3.3                        0.90              1            0  \n",
       "1        3.2                        0.74              0            1  \n",
       "2        3.3                        0.89              0            1  \n",
       "3        3.4                        1.00              0            1  \n",
       "4        2.4                        0.40              0            1  \n",
       "..       ...                         ...            ...          ...  \n",
       "578      1.6                        0.37              0            1  \n",
       "579      3.2                        1.10              0            1  \n",
       "580      3.2                        1.00              0            1  \n",
       "581      3.4                        1.00              0            1  \n",
       "582      4.4                        1.50              0            1  \n",
       "\n",
       "[583 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = encode_and_bind(X, 'Gender')\n",
    "X = X.drop(columns=['Gender','Age'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Bilirubin</th>\n",
       "      <th>Direct_Bilirubin</th>\n",
       "      <th>Alkaline_Phosphotase</th>\n",
       "      <th>Alamine_Aminotransferase</th>\n",
       "      <th>Aspartate_Aminotransferase</th>\n",
       "      <th>Total_Protiens</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin_and_Globulin_Ratio</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>578</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>579</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>98</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>245</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>184</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>582</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>216</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Total_Bilirubin  Direct_Bilirubin  Alkaline_Phosphotase  \\\n",
       "0                0.7               0.1                   187   \n",
       "1               10.9               5.5                   699   \n",
       "2                7.3               4.1                   490   \n",
       "3                1.0               0.4                   182   \n",
       "4                3.9               2.0                   195   \n",
       "..               ...               ...                   ...   \n",
       "578              0.5               0.1                   500   \n",
       "579              0.6               0.1                    98   \n",
       "580              0.8               0.2                   245   \n",
       "581              1.3               0.5                   184   \n",
       "582              1.0               0.3                   216   \n",
       "\n",
       "     Alamine_Aminotransferase  Aspartate_Aminotransferase  Total_Protiens  \\\n",
       "0                          16                          18             6.8   \n",
       "1                          64                         100             7.5   \n",
       "2                          60                          68             7.0   \n",
       "3                          14                          20             6.8   \n",
       "4                          27                          59             7.3   \n",
       "..                        ...                         ...             ...   \n",
       "578                        20                          34             5.9   \n",
       "579                        35                          31             6.0   \n",
       "580                        48                          49             6.4   \n",
       "581                        29                          32             6.8   \n",
       "582                        21                          24             7.3   \n",
       "\n",
       "     Albumin  Albumin_and_Globulin_Ratio  Gender_Female  Gender_Male  \n",
       "0        3.3                        0.90              1            0  \n",
       "1        3.2                        0.74              0            1  \n",
       "2        3.3                        0.89              0            1  \n",
       "3        3.4                        1.00              0            1  \n",
       "4        2.4                        0.40              0            1  \n",
       "..       ...                         ...            ...          ...  \n",
       "578      1.6                        0.37              0            1  \n",
       "579      3.2                        1.10              0            1  \n",
       "580      3.2                        1.00              0            1  \n",
       "581      3.4                        1.00              0            1  \n",
       "582      4.4                        1.50              0            1  \n",
       "\n",
       "[583 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(437, 10)\n",
      "(146, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "X_test  = X_test.values\n",
    "y_test  = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.80e+00, 9.00e+00, 2.72e+02, ..., 7.00e-01, 0.00e+00, 1.00e+00],\n",
       "       [8.60e+00, 4.00e+00, 2.98e+02, ..., 6.00e-01, 0.00e+00, 1.00e+00],\n",
       "       [2.70e+00, 1.40e+00, 1.05e+02, ..., 1.20e+00, 0.00e+00, 1.00e+00],\n",
       "       ...,\n",
       "       [9.00e-01, 2.00e-01, 2.24e+02, ..., 1.55e+00, 0.00e+00, 1.00e+00],\n",
       "       [8.00e-01, 2.00e-01, 1.30e+02, ..., 1.30e+00, 1.00e+00, 0.00e+00],\n",
       "       [8.00e-01, 2.00e-01, 1.58e+02, ..., 5.00e-01, 0.00e+00, 1.00e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training:\n",
      "\n",
      "Epoch 00001: accuracy improved from -inf to 0.03432, saving model to indian_liver.best.hdf5\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.03432\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.03432\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.03432\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.03432\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.03432\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.03432\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-b645bdf232e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                     verbose=0)\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 10 # num of epochs to test for\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "## Create our model\n",
    "tiny_model = Sequential()\n",
    "\n",
    "# 1st layer: input_dim=8, 12 nodes, RELU\n",
    "#model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "tiny_model.add(Dense(1000, input_dim=10, activation='relu'))\n",
    "# 2nd layer: 8 nodes, RELU\n",
    "tiny_model.add(Dense(2000, activation='relu'))\n",
    "#tiny_model.add(Dense(1000, activation='relu'))\n",
    "#tiny_model.add(Dense(300, activation='relu'))\n",
    "#tiny_model.add(Dense(200, activation='relu'))\n",
    "tiny_model.add(Dense(10, activation='relu'))\n",
    "# output layer: dim=1, activation sigmoid\n",
    "tiny_model.add(Dense(1, activation='sigmoid' ))\n",
    "\n",
    "tiny_model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "# checkpoint: store the best model\n",
    "ckpt_model = 'indian_liver.best.hdf5'\n",
    "checkpoint = ModelCheckpoint(ckpt_model, \n",
    "                            monitor='accuracy',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print('Starting training:')\n",
    "# train the model, store the results for plotting\n",
    "tiny_model_history = tiny_model.fit(X_train,\n",
    "                    y_train,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    callbacks=callbacks_list,\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training:\n",
      "\n",
      "Epoch 00001: accuracy improved from -inf to 0.11670, saving model to indian_liver_model2.best.hdf5\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00051: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00052: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00053: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00054: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00055: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00056: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00057: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00058: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00059: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00060: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00061: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00062: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00063: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00064: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00065: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00066: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00067: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00068: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00069: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00070: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00071: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00072: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00073: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00074: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00075: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00076: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00077: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00078: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00079: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00080: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00081: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00082: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00083: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00084: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00085: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00086: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00087: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00088: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00089: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00090: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00091: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00092: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00093: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00094: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00095: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00096: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00097: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00098: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00099: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00100: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00101: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00102: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00103: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00104: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00105: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00106: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00107: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00108: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00109: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00110: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00111: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00112: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00113: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00114: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00115: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00116: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00117: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00118: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00119: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00120: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00121: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00122: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00123: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00124: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00125: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00126: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00127: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00128: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00129: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00130: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00131: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00132: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00133: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00134: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00135: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00136: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00137: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00138: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00139: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00140: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00141: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00142: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00143: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00144: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00145: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00146: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00147: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00148: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00149: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00150: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00151: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00152: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00153: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00154: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00155: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00156: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00157: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00158: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00159: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00160: accuracy did not improve from 0.11670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00161: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00162: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00163: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00164: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00165: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00166: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00167: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00168: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00169: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00170: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00171: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00172: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00173: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00174: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00175: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00176: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00177: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00178: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00179: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00180: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00181: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00182: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00183: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00184: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00185: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00186: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00187: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00188: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00189: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00190: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00191: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00192: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00193: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00194: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00195: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00196: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00197: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00198: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00199: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00200: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00201: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00202: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00203: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00204: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00205: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00206: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00207: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00208: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00209: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00210: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00211: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00212: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00213: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00214: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00215: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00216: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00217: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00218: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00219: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00220: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00221: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00222: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00223: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00224: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00225: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00226: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00227: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00228: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00229: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00230: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00231: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00232: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00233: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00234: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00235: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00236: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00237: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00238: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00239: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00240: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00241: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00242: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00243: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00244: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00245: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00246: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00247: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00248: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00249: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00250: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00251: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00252: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00253: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00254: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00255: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00256: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00257: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00258: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00259: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00260: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00261: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00262: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00263: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00264: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00265: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00266: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00267: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00268: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00269: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00270: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00271: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00272: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00273: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00274: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00275: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00276: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00277: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00278: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00279: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00280: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00281: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00282: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00283: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00284: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00285: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00286: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00287: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00288: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00289: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00290: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00291: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00292: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00293: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00294: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00295: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00296: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00297: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00298: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00299: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00300: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00301: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00302: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00303: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00304: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00305: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00306: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00307: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00308: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00309: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00310: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00311: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00312: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00313: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00314: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00315: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00316: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00317: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00318: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00319: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00320: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00321: accuracy did not improve from 0.11670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00322: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00323: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00324: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00325: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00326: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00327: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00328: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00329: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00330: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00331: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00332: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00333: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00334: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00335: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00336: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00337: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00338: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00339: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00340: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00341: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00342: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00343: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00344: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00345: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00346: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00347: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00348: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00349: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00350: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00351: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00352: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00353: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00354: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00355: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00356: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00357: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00358: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00359: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00360: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00361: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00362: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00363: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00364: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00365: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00366: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00367: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00368: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00369: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00370: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00371: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00372: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00373: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00374: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00375: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00376: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00377: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00378: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00379: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00380: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00381: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00382: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00383: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00384: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00385: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00386: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00387: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00388: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00389: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00390: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00391: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00392: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00393: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00394: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00395: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00396: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00397: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00398: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00399: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00400: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00401: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00402: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00403: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00404: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00405: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00406: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00407: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00408: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00409: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00410: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00411: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00412: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00413: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00414: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00415: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00416: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00417: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00418: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00419: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00420: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00421: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00422: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00423: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00424: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00425: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00426: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00427: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00428: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00429: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00430: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00431: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00432: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00433: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00434: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00435: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00436: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00437: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00438: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00439: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00440: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00441: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00442: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00443: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00444: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00445: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00446: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00447: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00448: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00449: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00450: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00451: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00452: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00453: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00454: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00455: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00456: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00457: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00458: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00459: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00460: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00461: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00462: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00463: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00464: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00465: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00466: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00467: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00468: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00469: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00470: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00471: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00472: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00473: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00474: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00475: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00476: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00477: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00478: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00479: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00480: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00481: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00482: accuracy did not improve from 0.11670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00483: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00484: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00485: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00486: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00487: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00488: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00489: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00490: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00491: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00492: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00493: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00494: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00495: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00496: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00497: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00498: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00499: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00500: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00501: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00502: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00503: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00504: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00505: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00506: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00507: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00508: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00509: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00510: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00511: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00512: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00513: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00514: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00515: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00516: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00517: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00518: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00519: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00520: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00521: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00522: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00523: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00524: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00525: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00526: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00527: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00528: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00529: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00530: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00531: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00532: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00533: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00534: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00535: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00536: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00537: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00538: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00539: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00540: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00541: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00542: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00543: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00544: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00545: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00546: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00547: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00548: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00549: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00550: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00551: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00552: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00553: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00554: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00555: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00556: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00557: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00558: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00559: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00560: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00561: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00562: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00563: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00564: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00565: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00566: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00567: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00568: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00569: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00570: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00571: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00572: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00573: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00574: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00575: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00576: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00577: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00578: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00579: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00580: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00581: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00582: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00583: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00584: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00585: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00586: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00587: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00588: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00589: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00590: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00591: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00592: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00593: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00594: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00595: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00596: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00597: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00598: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00599: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00600: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00601: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00602: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00603: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00604: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00605: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00606: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00607: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00608: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00609: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00610: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00611: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00612: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00613: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00614: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00615: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00616: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00617: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00618: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00619: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00620: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00621: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00622: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00623: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00624: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00625: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00626: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00627: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00628: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00629: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00630: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00631: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00632: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00633: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00634: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00635: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00636: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00637: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00638: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00639: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00640: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00641: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00642: accuracy did not improve from 0.11670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00643: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00644: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00645: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00646: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00647: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00648: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00649: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00650: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00651: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00652: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00653: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00654: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00655: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00656: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00657: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00658: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00659: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00660: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00661: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00662: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00663: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00664: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00665: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00666: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00667: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00668: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00669: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00670: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00671: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00672: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00673: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00674: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00675: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00676: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00677: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00678: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00679: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00680: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00681: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00682: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00683: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00684: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00685: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00686: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00687: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00688: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00689: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00690: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00691: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00692: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00693: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00694: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00695: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00696: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00697: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00698: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00699: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00700: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00701: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00702: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00703: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00704: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00705: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00706: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00707: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00708: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00709: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00710: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00711: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00712: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00713: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00714: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00715: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00716: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00717: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00718: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00719: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00720: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00721: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00722: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00723: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00724: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00725: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00726: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00727: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00728: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00729: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00730: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00731: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00732: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00733: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00734: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00735: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00736: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00737: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00738: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00739: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00740: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00741: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00742: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00743: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00744: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00745: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00746: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00747: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00748: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00749: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00750: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00751: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00752: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00753: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00754: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00755: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00756: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00757: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00758: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00759: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00760: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00761: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00762: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00763: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00764: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00765: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00766: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00767: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00768: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00769: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00770: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00771: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00772: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00773: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00774: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00775: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00776: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00777: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00778: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00779: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00780: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00781: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00782: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00783: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00784: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00785: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00786: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00787: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00788: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00789: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00790: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00791: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00792: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00793: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00794: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00795: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00796: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00797: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00798: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00799: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00800: accuracy did not improve from 0.11670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00801: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00802: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00803: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00804: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00805: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00806: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00807: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00808: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00809: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00810: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00811: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00812: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00813: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00814: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00815: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00816: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00817: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00818: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00819: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00820: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00821: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00822: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00823: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00824: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00825: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00826: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00827: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00828: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00829: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00830: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00831: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00832: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00833: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00834: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00835: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00836: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00837: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00838: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00839: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00840: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00841: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00842: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00843: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00844: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00845: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00846: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00847: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00848: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00849: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00850: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00851: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00852: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00853: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00854: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00855: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00856: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00857: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00858: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00859: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00860: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00861: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00862: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00863: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00864: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00865: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00866: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00867: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00868: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00869: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00870: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00871: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00872: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00873: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00874: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00875: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00876: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00877: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00878: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00879: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00880: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00881: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00882: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00883: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00884: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00885: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00886: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00887: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00888: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00889: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00890: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00891: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00892: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00893: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00894: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00895: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00896: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00897: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00898: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00899: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00900: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00901: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00902: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00903: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00904: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00905: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00906: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00907: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00908: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00909: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00910: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00911: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00912: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00913: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00914: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00915: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00916: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00917: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00918: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00919: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00920: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00921: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00922: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00923: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00924: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00925: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00926: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00927: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00928: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00929: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00930: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00931: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00932: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00933: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00934: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00935: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00936: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00937: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00938: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00939: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00940: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00941: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00942: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00943: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00944: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00945: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00946: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00947: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00948: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00949: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00950: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00951: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00952: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00953: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00954: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00955: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00956: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00957: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00958: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00959: accuracy did not improve from 0.11670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00960: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00961: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00962: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00963: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00964: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00965: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00966: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00967: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00968: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00969: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00970: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00971: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00972: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00973: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00974: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00975: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00976: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00977: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00978: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00979: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00980: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00981: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00982: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00983: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00984: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00985: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00986: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00987: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00988: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00989: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00990: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00991: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00992: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00993: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00994: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00995: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00996: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00997: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00998: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 00999: accuracy did not improve from 0.11670\n",
      "\n",
      "Epoch 01000: accuracy did not improve from 0.11670\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1000  # num of epochs to test for\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "## Create our model\n",
    "model2 = Sequential()\n",
    "\n",
    "# 1st layer: input_dim=8, 12 nodes, RELU\n",
    "#model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "model2.add(Dense(16, input_dim=10, activation='relu'))\n",
    "# 2nd layer: 8 nodes, RELU\n",
    "#tiny_model.add(Dense(8, activation='relu'))\n",
    "#tiny_model.add(Dense(8, activation='relu'))\n",
    "# output layer: dim=1, activation sigmoid\n",
    "model2.add(Dense(1, activation='sigmoid' ))\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "# checkpoint: store the best model\n",
    "ckpt_model = 'indian_liver_model2.best.hdf5'\n",
    "checkpoint = ModelCheckpoint(ckpt_model, \n",
    "                            monitor='accuracy',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print('Starting training:')\n",
    "# train the model, store the results for plotting\n",
    "model2_history = model2.fit(X_train,\n",
    "                    y_train,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    callbacks=callbacks_list,\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
