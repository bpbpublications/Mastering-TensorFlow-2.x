{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prunings_samples_rd.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNXqgZTJHVfASoBgvrtnlTm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajdeepd/tensorflow_2.0_book_code/blob/master/ch09/prunings_samples_rd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM2sFR5mK1zF"
      },
      "source": [
        "# Pruning Examples for TensorFlow 2.x\n",
        "In magnitude based weight pruning model sparsity is achieved by gradually zeroing out model weights without compromising accuracy. It helps improve model compression by factor of 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWRaFkCeLExi"
      },
      "source": [
        "## Install and Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df1lejBuEI7G"
      },
      "source": [
        "! pip install -q tensorflow-model-optimization\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_model_optimization as tfmot\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lTfx3lLLJtW"
      },
      "source": [
        "## Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dwyn5D-UEfKP"
      },
      "source": [
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "import tempfile\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Co3hxxzLTPc"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvoLdYVVUT3M",
        "outputId": "eb9bc30d-fd14-4f4c-8a33-dbbf364f3139"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 and 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Define the model architecture.\n",
        "model_mnist = keras.Sequential([\n",
        "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
        "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Train the digit classification model\n",
        "model_mnist.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_mnist.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=4, validation_split=0.1,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "1688/1688 [==============================] - 19s 11ms/step - loss: 0.3288 - accuracy: 0.9063 - val_loss: 0.1459 - val_accuracy: 0.9608\n",
            "Epoch 2/4\n",
            "1688/1688 [==============================] - 18s 11ms/step - loss: 0.1398 - accuracy: 0.9593 - val_loss: 0.0936 - val_accuracy: 0.9755\n",
            "Epoch 3/4\n",
            "1688/1688 [==============================] - 18s 11ms/step - loss: 0.0932 - accuracy: 0.9729 - val_loss: 0.0755 - val_accuracy: 0.9802\n",
            "Epoch 4/4\n",
            "1688/1688 [==============================] - 18s 11ms/step - loss: 0.0745 - accuracy: 0.9782 - val_loss: 0.0672 - val_accuracy: 0.9833\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb27f9ac6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB0-Dz2iUN2-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHznLIPXLVV7"
      },
      "source": [
        "## Prune all the Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOUoyAV3Exf8",
        "outputId": "09f1b34e-051c-46a9-ef56-c84244650b2c"
      },
      "source": [
        "\n",
        "_, pretrained_weights = tempfile.mkstemp('.tf')\n",
        "model_mnist.save_weights(pretrained_weights)\n",
        "\n",
        "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(model_mnist)\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:2223: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "prune_low_magnitude_reshape_ (None, 28, 28, 1)         1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv2d_3 (None, 26, 26, 12)        230       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 13, 13, 12)        1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten_ (None, 2028)              1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_3  (None, 10)                40572     \n",
            "=================================================================\n",
            "Total params: 40,805\n",
            "Trainable params: 20,410\n",
            "Non-trainable params: 20,395\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPDNwmE3cUcI"
      },
      "source": [
        "## Prune Some Layers \n",
        "\n",
        "Functional and Sequential example.\n",
        "Tips for better model accuracy:\n",
        "\n",
        "It's generally better to finetune with pruning as opposed to training from scratch.\n",
        "Try pruning the later layers instead of the first layers.\n",
        "Avoid pruning critical layers (e.g. attention mechanism).\n",
        "More:\n",
        "\n",
        "The tfmot.sparsity.keras.prune_low_magnitude API docs provide details on how to vary the pruning configuration per layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSE22sGscdda",
        "outputId": "82c425f8-e303-4033-ffb8-4ba9ae0d3bd0"
      },
      "source": [
        "\n",
        "# Helper function uses `prune_low_magnitude` to make only the \n",
        "# Dense layers train with pruning.\n",
        "def apply_pruning_to_dense(layer):\n",
        "  if isinstance(layer, tf.keras.layers.Dense):\n",
        "    return tfmot.sparsity.keras.prune_low_magnitude(layer)\n",
        "  return layer\n",
        "\n",
        "# Use `tf.keras.models.clone_model` to apply `apply_pruning_to_dense` \n",
        "# to the layers of the model.\n",
        "model_for_pruning = tf.keras.models.clone_model(\n",
        "    model_mnist,\n",
        "    clone_function=apply_pruning_to_dense,\n",
        ")\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_3 (Reshape)          (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 26, 26, 12)        120       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 12)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2028)              0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_3  (None, 10)                40572     \n",
            "=================================================================\n",
            "Total params: 40,692\n",
            "Trainable params: 20,410\n",
            "Non-trainable params: 20,282\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:2223: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmN8ERnXc0KC"
      },
      "source": [
        "### Sequential Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rvGRMB4c4Yu",
        "outputId": "021a7a10-634d-484c-ed73-fa7ad4dc181d"
      },
      "source": [
        "# Use `prune_low_magnitude` to make the `Dense` layer train with pruning.\n",
        "input_shape = [10]\n",
        "\n",
        "model_for_pruning = tf.keras.Sequential([\n",
        "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
        "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  keras.layers.Flatten(),\n",
        "  tfmot.sparsity.keras.prune_low_magnitude(keras.layers.Dense(10))\n",
        "])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_4 (Reshape)          (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 26, 26, 12)        120       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 12)        0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 2028)              0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_7  (None, 10)                40572     \n",
            "=================================================================\n",
            "Total params: 40,692\n",
            "Trainable params: 20,410\n",
            "Non-trainable params: 20,282\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:2223: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ]
        }
      ]
    }
  ]
}