{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sample_DQN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMw3UfBORUr/avETvxT33Mq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajdeepd/tensorflow_2.0_book_code/blob/master/ch09/Sample_DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7R8WM6iGQCs",
        "outputId": "3bd5df3b-e8b2-49e1-e415-5c5e4363a214"
      },
      "source": [
        "!sudo apt-get install -y xvfb ffmpeg\n",
        "!pip install 'imageio==2.4.0'\n",
        "#!pip install pyvirtualdisplay\n",
        "!pip install tf-agents"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 31 not upgraded.\n",
            "Need to get 784 kB of archives.\n",
            "After this operation, 2,270 kB of additional disk space will be used.\n",
            "Ign:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.8\n",
            "Err:1 http://security.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.8\n",
            "  404  Not Found [IP: 91.189.88.152 80]\n",
            "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/universe/x/xorg-server/xvfb_1.19.6-1ubuntu4.8_amd64.deb  404  Not Found [IP: 91.189.88.152 80]\n",
            "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n",
            "Collecting imageio==2.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/64/8e2bb6aac43d6ed7c2d9514320b43d5e80c00f150ee2b9408aee24359e6d/imageio-2.4.0.tar.gz (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 20.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.0) (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.0) (7.1.2)\n",
            "Building wheels for collected packages: imageio\n",
            "  Building wheel for imageio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imageio: filename=imageio-2.4.0-cp37-none-any.whl size=3303881 sha256=0d5ec576cafd1849185cb4eea02c76393a3e78eb2ea5ecd5c19b668b64c57fac\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/83/88/a1cba54ac06395d9e4ddcd9cf06911cd0b26cd78af9a61071b\n",
            "Successfully built imageio\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: imageio\n",
            "  Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "Successfully installed imageio-2.4.0\n",
            "Collecting tf-agents\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/cd/a0710b1caae042b7a4d54fc74073fb4df7adf073934798443bdc0059813a/tf_agents-0.7.1-py3-none-any.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 21.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (1.12.1)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (0.4.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (0.12.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (1.19.5)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (1.3.0)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (3.7.4.3)\n",
            "Requirement already satisfied: tensorflow-probability>=0.12.1 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (0.12.1)\n",
            "Requirement already satisfied: gym>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (0.17.3)\n",
            "Requirement already satisfied: pillow>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.11.3->tf-agents) (54.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.12.1->tf-agents) (4.4.2)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.12.1->tf-agents) (0.3.3)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.12.1->tf-agents) (0.1.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.0->tf-agents) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.0->tf-agents) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17.0->tf-agents) (0.16.0)\n",
            "Installing collected packages: tf-agents\n",
            "Successfully installed tf-agents-0.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k2WE0MzGVkk"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from absl.testing import parameterized\n",
        "import tensorflow as tf  # pylint: disable=g-explicit-tensorflow-version-import\n",
        "\n",
        "import tf_agents\n",
        "import sys\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.networks import network\n",
        "from tf_agents.networks import q_network\n",
        "from tf_agents.networks import sequential\n",
        "from tf_agents.networks import test_utils as networks_test_utils\n",
        "from tf_agents.specs import tensor_spec\n",
        "from tf_agents.trajectories import policy_step\n",
        "from tf_agents.trajectories import test_utils as trajectories_test_utils\n",
        "from tf_agents.trajectories import time_step as ts\n",
        "from tf_agents.trajectories import trajectory\n",
        "from tf_agents.utils import common\n",
        "from tf_agents.utils import test_utils"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhRcxmL-HQCo"
      },
      "source": [
        "class DummyNet(network.Network):\n",
        "\n",
        "  def __init__(self,\n",
        "               observation_spec,\n",
        "               action_spec,\n",
        "               l2_regularization_weight=0.0,\n",
        "               name=None):\n",
        "    super(DummyNet, self).__init__(\n",
        "        observation_spec, state_spec=(), name=name)\n",
        "    num_actions = action_spec.maximum - action_spec.minimum + 1\n",
        "\n",
        "    # Store custom layers that can be serialized through the Checkpointable API.\n",
        "    self._dummy_layers = [\n",
        "        tf.keras.layers.Dense(\n",
        "            num_actions,\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(\n",
        "                l2_regularization_weight),\n",
        "            kernel_initializer=tf.constant_initializer([[num_actions, 1],\n",
        "                                                        [1, 1]]),\n",
        "            bias_initializer=tf.constant_initializer([[1], [1]]))\n",
        "    ]\n",
        "\n",
        "  def call(self, inputs, step_type=None, network_state=()):\n",
        "    del step_type\n",
        "    inputs = tf.cast(inputs, tf.float32)\n",
        "    for layer in self._dummy_layers:\n",
        "      inputs = layer(inputs)\n",
        "    return inputs, network_state"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQzZPWRm3kQL"
      },
      "source": [
        "class DqnAgentBase(tf.test.TestCase, parameterized.TestCase):\n",
        "\n",
        "  def setUp(self):\n",
        "\n",
        "    super(DqnAgentBase, self).setUp()\n",
        "    self._observation_spec = tensor_spec.TensorSpec([2], tf.float32)\n",
        "    self._time_step_spec = ts.time_step_spec(self._observation_spec)\n",
        "    self._action_spec = tensor_spec.BoundedTensorSpec((), tf.int32, 0, 1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NQv7kEG1Vb5"
      },
      "source": [
        "### DqnAgent \n",
        "#### With Changed Optimal Actions\n",
        "\n",
        " Using the kernel initializer `[[2, 1], [1, 1]]` and bias initializer\n",
        " `[[1], [1]]` from DummyNet above, we can calculate the following values:\n",
        " \n",
        " ```\n",
        " Q-value for first observation/action pair: 2 * 1 + 1 * 2 + 1 = 5\n",
        " Q-value for second observation/action pair: 1 * 3 + 1 * 4 + 1 = 8\n",
        " (Here we use the second row of the kernel initializer above, since the\n",
        " chosen action is now 1 instead of 0.)\n",
        " ```\n",
        "\n",
        " For the target Q-values here, note that since we've replaced `5` and `7` with\n",
        " `-5` and `-7`, it is better to use action `1` with a kernel of `[1, 1]` instead of action `0` with a kernel of `[2, 1]`.\n",
        "\n",
        " ```\n",
        " Target Q-value for first next_observation: 1 * -5 + 1 * 6 + 1 = 2\n",
        " Target Q-value for second next_observation: 1 * -7 + 1 * 8 + 1 = 2\n",
        " TD targets: 10 + 0.9 * 2 = 11.8 and 20 + 0.9 * 2 = 21.8\n",
        " TD errors: 11.8 - 5 = 6.8 and 21.8 - 8 = 13.8\n",
        " TD loss: 6.3 and 13.3 (Huber loss subtracts 0.5)\n",
        " Overall loss: (6.3 + 13.3) / 2 = 9.8\n",
        " ```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZFvLgNM1Tpm"
      },
      "source": [
        "class DqnAgentSampleOne(DqnAgentBase):\n",
        "\n",
        "  def setUp(self):\n",
        "    super(DqnAgentSampleOne, self).setUp()\n",
        "  \n",
        "  def runLossWithChangedOptimalActions(self):\n",
        "    q_net = DummyNet(self._observation_spec, self._action_spec)\n",
        "    #<class 'tf_agents.agents.dqn.dqn_agent.DdqnAgent'>\n",
        "    agent = tf_agents.agents.dqn.dqn_agent.DdqnAgent(\n",
        "        self._time_step_spec,\n",
        "        self._action_spec,\n",
        "        q_network=q_net,\n",
        "        optimizer=None)\n",
        "\n",
        "    observations = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n",
        "    time_steps = ts.restart(observations, batch_size=2)\n",
        "\n",
        "    actions = tf.constant([0, 1], dtype=tf.int32)\n",
        "    action_steps = policy_step.PolicyStep(actions)\n",
        "\n",
        "    rewards = tf.constant([10, 20], dtype=tf.float32)\n",
        "    discounts = tf.constant([0.9, 0.9], dtype=tf.float32)\n",
        "\n",
        "    # Note that instead of [[5, 6], [7, 8]] as before, we now have -5 and -7.\n",
        "    next_observations = tf.constant([[-5, 6], [-7, 8]], dtype=tf.float32)\n",
        "    next_time_steps = ts.transition(next_observations, rewards, discounts)\n",
        "\n",
        "    experience = trajectories_test_utils.stacked_trajectory_from_transition(\n",
        "        time_steps, action_steps, next_time_steps)\n",
        "\n",
        "    loss, _ = agent._loss(experience)\n",
        "\n",
        "    self.evaluate(tf.compat.v1.global_variables_initializer())\n",
        "    loss_evaluate = self.evaluate(loss)\n",
        "    tf.print(\"loss:\", loss, output_stream=sys.stdout)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY3Kte_XHf0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc06a48c-bf8f-402b-980d-4452482340cd"
      },
      "source": [
        "sampleOne = DqnAgentSampleOne()\n",
        "sampleOne.setUp()\n",
        "sampleOne.runLossWithChangedOptimalActions()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 9.79999924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ori06gX0C3AG"
      },
      "source": [
        "### Multiple Episodes"
      ]
    }
  ]
}
