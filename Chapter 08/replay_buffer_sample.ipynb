{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay Buffers\n",
    "## Introduction\n",
    "\n",
    "Reinforcement learning algorithms use replay buffers to store trajectories of experience when executing a policy in an environment. During training, replay buffers are queried for a subset of the trajectories (either a sequential subset or a sample) to \"replay\" the agent's experience.\n",
    "\n",
    "In this notebook, we explore two types of replay buffers: python-backed and tensorflow-backed, sharing a common API. In the following sections, we describe the API, each of the buffer implementations and how to use them during data collection training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/Users/rdua/opt/anaconda3/bin/python -m pip install --upgrade pip\n",
    "#!sudo /Users/rdua/opt/anaconda3/bin/pip install tensorflow==2.4.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tf_agents\n",
    "except ModuleNotFoundError:\n",
    "    print('tf_agents not installed')\n",
    "    !/Users/rdua/opt/anaconda3/bin/pip install tf-agents\n",
    "      \n",
    "#!/Users/rdua/pip install tf-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tf_agents import specs\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.networks import q_network\n",
    "from tf_agents.replay_buffers import py_uniform_replay_buffer\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFUniformReplayBuffer\n",
    "\n",
    "`TFUniformReplayBuffer` is the most commonly used replay buffer in TF-Agents, hence we are using it in our tutorial here. In `TFUniformReplayBuffer` the backing buffer storage is done by tensorflow variables and thus is part of the compute graph. \n",
    "\n",
    "The buffer stores batches of elements and has a maximum capacity `max_length` elements per batch segment. Thus, the total buffer capacity is `batch_size` x `max_length` elements. The elements stored in the buffer must all have a matching data spec. When the replay buffer is used for data collection, the spec is the agent's collect data spec.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spec =  (\n",
    "        tf.TensorSpec([3], tf.float32, 'action'),\n",
    "        (\n",
    "            tf.TensorSpec([5], tf.float32, 'lidar'),\n",
    "            tf.TensorSpec([3, 2], tf.float32, 'camera')\n",
    "        )\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "max_length = 1000\n",
    "\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec,\n",
    "    batch_size=batch_size,\n",
    "    max_length=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to Buffer\n",
    "\n",
    "```\n",
    "tf_agents.replay_buffers.replay_buffer.ReplayBuffer(\n",
    "    data_spec, capacity, stateful_dataset=False\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "add_batch(\n",
    "    items\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = tf.constant(1 * np.ones(\n",
    "    data_spec[0].shape.as_list(), dtype=np.float32))\n",
    "lidar = tf.constant(\n",
    "    2 * np.ones(data_spec[1][0].shape.as_list(), dtype=np.float32))\n",
    "camera = tf.constant(\n",
    "    3 * np.ones(data_spec[1][1].shape.as_list(), dtype=np.float32))\n",
    "  \n",
    "values = (action, (lidar, camera))\n",
    "values_batched = tf.nest.map_structure(lambda t: tf.stack([t] * batch_size),\n",
    "                                       values)\n",
    "  \n",
    "replay_buffer.add_batch(values_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from the buffer\n",
    "There are three ways to read data from the TFUniformReplayBuffer:\n",
    "\n",
    "* `get_next()` - returns one sample from the buffer. The sample batch size and number of timesteps returned can be specified via arguments to this method.\n",
    "* `as_dataset()` - returns the replay buffer as a tf.data.Dataset. One can then create a dataset iterator and iterate through the samples of the items in the buffer.\n",
    "* `gather_all()` - returns all the items in the buffer as a Tensor with shape [batch, time, data_spec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Iterator trajectories:\n",
      "[(TensorShape([4, 2, 3]), (TensorShape([4, 2, 5]), TensorShape([4, 2, 3, 2]))), (TensorShape([4, 2, 3]), (TensorShape([4, 2, 5]), TensorShape([4, 2, 3, 2]))), (TensorShape([4, 2, 3]), (TensorShape([4, 2, 5]), TensorShape([4, 2, 3, 2])))]\n",
      "Trajectories from gather all:\n",
      "(TensorShape([32, 46, 3]), (TensorShape([32, 46, 5]), TensorShape([32, 46, 3, 2])))\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "  replay_buffer.add_batch(values_batched)\n",
    "sample = replay_buffer.get_next(sample_batch_size=10, num_steps=1)\n",
    "\n",
    "print(len(sample))\n",
    "\n",
    "# Convert the replay buffer to a tf.data.Dataset and iterate through it\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    sample_batch_size=4,\n",
    "    num_steps=2)\n",
    "\n",
    "iterator = iter(dataset)\n",
    "print(\"Iterator trajectories:\")\n",
    "trajectories = []\n",
    "for _ in range(3):\n",
    "  t, _ = next(iterator)\n",
    "  trajectories.append(t)\n",
    "  \n",
    "print(tf.nest.map_structure(lambda t: t.shape, trajectories))\n",
    "\n",
    "# Read all elements in the replay buffer:\n",
    "trajectories = replay_buffer.gather_all()\n",
    "\n",
    "print(\"Trajectories from gather all:\")\n",
    "print(tf.nest.map_structure(lambda t: t.shape, trajectories))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
